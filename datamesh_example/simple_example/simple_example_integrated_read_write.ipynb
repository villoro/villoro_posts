{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T15:18:13.062613Z",
     "start_time": "2021-11-26T15:18:12.287613Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "from typing import List\n",
    "\n",
    "from abc import ABC\n",
    "from abc import abstractmethod\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "from create_data import recreate_databases, create_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T15:18:21.199544Z",
     "start_time": "2021-11-26T15:18:13.065613Z"
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"DM\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T15:18:45.890328Z",
     "start_time": "2021-11-26T15:18:21.208472Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-26 16:18:21.209 | INFO     | create_data:recreate_databases:28 - Removing spark warehouse (path = 'spark-warehouse')\n",
      "2021-11-26 16:18:21.249 | INFO     | create_data:recreate_databases:32 - Creating database 'standardized_glovo_live'\n",
      "2021-11-26 16:18:23.557 | INFO     | create_data:recreate_databases:32 - Creating database 'mpcustomer_custom_events'\n",
      "2021-11-26 16:18:23.602 | INFO     | create_data:recreate_databases:32 - Creating database 'mpcustomer_screen_views'\n",
      "2021-11-26 16:18:23.637 | INFO     | create_data:recreate_databases:32 - Creating database 'enriched_custom_events'\n",
      "2021-11-26 16:18:23.669 | INFO     | create_data:recreate_databases:32 - Creating database 'enriched_screen_views'\n",
      "2021-11-26 16:18:23.710 | INFO     | create_data:create_table:63 - Creating table 'standardized_glovo_live.cities'\n",
      "2021-11-26 16:18:32.181 | INFO     | create_data:create_table:63 - Creating table 'standardized_glovo_live.devices'\n",
      "2021-11-26 16:18:39.221 | INFO     | create_data:create_table:63 - Creating table 'mpcustomer_custom_events.order_created'\n"
     ]
    }
   ],
   "source": [
    "recreate_databases(spark)\n",
    "create_tables(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T15:18:45.921329Z",
     "start_time": "2021-11-26T15:18:45.893330Z"
    }
   },
   "outputs": [],
   "source": [
    "class Loader(ABC):\n",
    "    def __init__(self, spark: SparkSession):\n",
    "        self.spark = spark\n",
    "        self.sdf = self.load()\n",
    "\n",
    "    def load(self) -> DataFrame:\n",
    "        sdf = self.spark.table(f\"{self.database_in}.{self.name_in}\")\n",
    "        return self.select(sdf)\n",
    "\n",
    "    def select(self, sdf):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def database_in(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def name_in(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class LoaderLiveDB(Loader):\n",
    "    database_in = \"standardized_glovo_live\"\n",
    "    \n",
    "class LoaderCustomEvent(Loader):\n",
    "    database_in = \"mpcustomer_custom_events\"\n",
    "    \n",
    "class LoaderScreenView(Loader):\n",
    "    database_in = \"mpcustomer_screen_views\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T15:18:45.936329Z",
     "start_time": "2021-11-26T15:18:45.924330Z"
    }
   },
   "outputs": [],
   "source": [
    "class Writer(ABC):\n",
    "    \n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def database_out(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def name_out(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def write(self):\n",
    "        self.sdf.write.format(\"parquet\").saveAsTable(f\"{self.database_out}.{self.name_out}\")\n",
    "\n",
    "class WriterCustomEvent(Writer):\n",
    "    database_out = \"enriched_custom_events\"\n",
    "\n",
    "class WriterScreenView(Writer):\n",
    "    database_out = \"enriched_screen_views\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T15:18:45.951328Z",
     "start_time": "2021-11-26T15:18:45.939330Z"
    }
   },
   "outputs": [],
   "source": [
    "class CitiesPort(LoaderLiveDB):\n",
    "    name_in = \"cities\"\n",
    "    \n",
    "    code = \"code\"\n",
    "    time_zone = \"time_zone\"\n",
    "    country_code = \"country_code\"\n",
    "    \n",
    "    def select(self, sdf) -> DataFrame:\n",
    "        return sdf.select(self.code, self.time_zone, self.country_code)\n",
    "\n",
    "\n",
    "class DevicesPort(LoaderLiveDB):\n",
    "    name_in = \"devices\"\n",
    "    \n",
    "    device_id = \"custom_attributes__device_id\"\n",
    "    experiment_score = \"device_experiment_score\"\n",
    "\n",
    "    def select(self, sdf) -> DataFrame:\n",
    "        return sdf.selectExpr(\n",
    "            f\"id AS {self.device_id}\",\n",
    "            f\"experiment_score AS {self.experiment_score}\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T15:18:45.967329Z",
     "start_time": "2021-11-26T15:18:45.954329Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomEventPort(LoaderCustomEvent, WriterCustomEvent):\n",
    "    \n",
    "    creation_date = \"p_creation_date\"\n",
    "    city = \"custom_attributes__city\"\n",
    "    \n",
    "    def __init__(self, spark, exec_date: date, n_days: int):\n",
    "        self.exec_date = exec_date\n",
    "        self.n_days = n_days\n",
    "\n",
    "        super().__init__(spark)\n",
    "\n",
    "    def select(self, sdf) -> DataFrame:\n",
    "        \n",
    "        start = self.exec_date - timedelta(days=self.n_days)\n",
    "        end = self.exec_date\n",
    "\n",
    "        return sdf.filter(\n",
    "            f\"{self.creation_date} BETWEEN '{start:%Y-%m-%d}' AND '{end:%Y-%m-%d}'\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T15:18:45.982330Z",
     "start_time": "2021-11-26T15:18:45.971330Z"
    }
   },
   "outputs": [],
   "source": [
    "class OrderCreatedPort(CustomEventPort):\n",
    "    name_in = \"order_created\"\n",
    "    name_out = \"order_created\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T15:18:45.998344Z",
     "start_time": "2021-11-26T15:18:45.985328Z"
    }
   },
   "outputs": [],
   "source": [
    "class Transformation(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def apply(self, sdf: DataFrame) -> DataFrame:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "class Table(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def sdf(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T15:18:46.014329Z",
     "start_time": "2021-11-26T15:18:46.000328Z"
    }
   },
   "outputs": [],
   "source": [
    "class AddTimezone(Transformation):\n",
    "    def __init__(self, cities: CitiesPort):\n",
    "        self.cities = cities\n",
    "\n",
    "    def apply(self, table: Table) -> Table:\n",
    "        \n",
    "        table.sdf = table.sdf.join(\n",
    "            F.broadcast(self.cities.sdf),\n",
    "            on=table.sdf[table.city] == self.cities.sdf[self.cities.code],\n",
    "            how=\"left\",\n",
    "        ).drop(self.cities.code)\n",
    "\n",
    "        return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T15:18:46.029350Z",
     "start_time": "2021-11-26T15:18:46.017328Z"
    }
   },
   "outputs": [],
   "source": [
    "class TransformLinearlyJob:\n",
    "\n",
    "    @abstractmethod\n",
    "    def transformations(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def run(self):\n",
    "        for transformation in self.transformations:\n",
    "            self.table = transformation.apply(self.table)\n",
    "\n",
    "        self.table.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T15:18:46.044329Z",
     "start_time": "2021-11-26T15:18:46.031329Z"
    }
   },
   "outputs": [],
   "source": [
    "class EnrichActionJob(TransformLinearlyJob):\n",
    "    \n",
    "    def __init__(self, spark, exec_date, n_days):\n",
    "        self.spark = spark\n",
    "        self.exec_date = exec_date\n",
    "        self.n_days = n_days\n",
    "        \n",
    "        # Create the table\n",
    "        self.table = self.action_port(spark, exec_date, n_days)\n",
    "        \n",
    "        # Set transformations\n",
    "        self.transformations = self.get_transformations()\n",
    "\n",
    "    def get_transformations(self):\n",
    "        return [\n",
    "#             AddTimezone(CitiesPort(self.spark))\n",
    "        ]\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def action_port(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    \n",
    "class EnrichCEOrderCreatedJob(EnrichActionJob):\n",
    "    action_port = OrderCreatedPort\n",
    "    \n",
    "    # Example of how to add extra transformations for one event\n",
    "    def get_transformations(self):\n",
    "        return super().get_transformations() + [\n",
    "            AddTimezone(CitiesPort(self.spark))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order Created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T15:18:48.213330Z",
     "start_time": "2021-11-26T15:18:46.047329Z"
    }
   },
   "outputs": [],
   "source": [
    "order_created_job = EnrichCEOrderCreatedJob(\n",
    "    spark=spark,\n",
    "    exec_date=date(2021, 11, 19),\n",
    "    n_days=3\n",
    ")\n",
    "order_created_job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T15:18:48.651331Z",
     "start_time": "2021-11-26T15:18:48.217331Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+---------------+-------------+------------+\n",
      "|custom_attributes__city|p_creation_date|    time_zone|country_code|\n",
      "+-----------------------+---------------+-------------+------------+\n",
      "|                    BCN|     2021-11-19|Europe/Madrid|          ES|\n",
      "|                    BCN|     2021-11-18|Europe/Madrid|          ES|\n",
      "|                    CAG|     2021-11-17|  Europe/Rome|          IT|\n",
      "+-----------------------+---------------+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.table(f\"{OrderCreatedPort.database_out}.{OrderCreatedPort.name_out}\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
