{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T16:36:17.516934Z",
     "start_time": "2021-11-19T16:36:17.506934Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "from typing import List\n",
    "\n",
    "from abc import ABC\n",
    "from abc import abstractmethod\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "from create_data import recreate_databases, create_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T16:34:26.139028Z",
     "start_time": "2021-11-19T16:34:22.317934Z"
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"DM\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T16:34:38.883041Z",
     "start_time": "2021-11-19T16:34:26.748628Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-19 17:34:26.749 | INFO     | create_data:recreate_databases:24 - Creating database 'standardized_glovo_live'\n",
      "2021-11-19 17:34:27.901 | INFO     | create_data:recreate_databases:24 - Creating database 'mpcustomer_custom_events'\n",
      "2021-11-19 17:34:27.922 | INFO     | create_data:recreate_databases:24 - Creating database 'mpcustomer_screen_views'\n",
      "2021-11-19 17:34:27.940 | INFO     | create_data:recreate_databases:24 - Creating database 'enriched_custom_events'\n",
      "2021-11-19 17:34:27.956 | INFO     | create_data:recreate_databases:24 - Creating database 'enriched_screen_views'\n",
      "2021-11-19 17:34:27.972 | INFO     | create_data:create_table:55 - Creating table 'standardized_glovo_live.cities'\n",
      "2021-11-19 17:34:32.197 | INFO     | create_data:create_table:55 - Creating table 'standardized_glovo_live.devices'\n",
      "2021-11-19 17:34:35.542 | INFO     | create_data:create_table:55 - Creating table 'mpcustomer_custom_events.order_created'\n"
     ]
    }
   ],
   "source": [
    "recreate_databases(spark)\n",
    "create_tables(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T16:34:38.899010Z",
     "start_time": "2021-11-19T16:34:38.884040Z"
    }
   },
   "outputs": [],
   "source": [
    "class Loader(ABC):\n",
    "    def __init__(self, spark: SparkSession):\n",
    "        self.spark = spark\n",
    "        self.sdf = self.load()\n",
    "\n",
    "    @abstractmethod\n",
    "    def load(self) -> DataFrame:\n",
    "        raise NotImplementedError\n",
    "\n",
    "class LoaderLiveDB(Loader):\n",
    "    database_in = \"standardized_glovo_live\"\n",
    "    \n",
    "class LoaderCustomEvent(Loader):\n",
    "    database_in = \"mpcustomer_custom_events\"\n",
    "    \n",
    "class LoaderScreenView(Loader):\n",
    "    database_in = \"mpcustomer_screen_views\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T16:34:38.913972Z",
     "start_time": "2021-11-19T16:34:38.901012Z"
    }
   },
   "outputs": [],
   "source": [
    "class Writer(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def write(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class WriterCustomEvent(Writer):\n",
    "    database_out = \"enriched_custom_events\"\n",
    "\n",
    "class WriterScreenView(Writer):\n",
    "    database_out = \"enriched_screen_views\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T16:34:38.929874Z",
     "start_time": "2021-11-19T16:34:38.914989Z"
    }
   },
   "outputs": [],
   "source": [
    "class CitiesPort(LoaderLiveDB):\n",
    "    code = \"code\"\n",
    "    time_zone = \"time_zone\"\n",
    "    country_code = \"country_code\"\n",
    "    \n",
    "    def load(self) -> DataFrame:\n",
    "        sdf = self.spark.table(f\"{self.database_in}.cities\")\n",
    "        return sdf.select(self.code, self.time_zone, self.country_code)\n",
    "\n",
    "\n",
    "class DevicesPort(LoaderLiveDB):\n",
    "    device_id = \"custom_attributes__device_id\"\n",
    "    experiment_score = \"device_experiment_score\"\n",
    "\n",
    "    def load(self) -> DataFrame:\n",
    "        sdf = self.spark.table(f\"{self.database_in}.devices\")\n",
    "        return sdf.selectExpr(\n",
    "            f\"id AS {self.device_id}\",\n",
    "            f\"experiment_score AS {self.experiment_score}\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T16:36:54.509012Z",
     "start_time": "2021-11-19T16:36:54.490992Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomEventPort(LoaderCustomEvent, WriterCustomEvent):\n",
    "    \n",
    "    creation_date = \"p_creation_date\"\n",
    "    city = \"custom_attributes__city\"\n",
    "    \n",
    "    def __init__(self, spark, exec_date: date, n_days: int):\n",
    "        self.exec_date = exec_date\n",
    "        self.n_days = n_days\n",
    "\n",
    "        super().__init__(spark)\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def name(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def load(self) -> DataFrame:\n",
    "        \n",
    "        start = self.exec_date - timedelta(days=self.n_days)\n",
    "        end = self.exec_date\n",
    "        \n",
    "        sdf = self.spark.table(f\"{self.database_in}.{self.name}\")\n",
    "\n",
    "        return sdf.filter(\n",
    "            f\"{self.creation_date} BETWEEN '{start:%Y-%m-%d}' AND '{end:%Y-%m-%d}'\"\n",
    "        )\n",
    "\n",
    "    def write(self):\n",
    "        self.sdf.write.format(\"parquet\").saveAsTable(f\"{self.database_out}.{self.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T16:36:55.582989Z",
     "start_time": "2021-11-19T16:36:55.577991Z"
    }
   },
   "outputs": [],
   "source": [
    "class OrderCreatedPort(CustomEventPort):\n",
    "    name = \"order_created\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T16:36:56.490389Z",
     "start_time": "2021-11-19T16:36:56.482406Z"
    }
   },
   "outputs": [],
   "source": [
    "class Transformation(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def apply(self, sdf: DataFrame) -> DataFrame:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "class Table(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def sdf(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T16:37:43.084303Z",
     "start_time": "2021-11-19T16:37:43.066158Z"
    }
   },
   "outputs": [],
   "source": [
    "class AddTimezone(Transformation):\n",
    "    def __init__(self, cities: CitiesPort):\n",
    "        self.cities = cities\n",
    "\n",
    "    def apply(self, table: Table) -> Table:\n",
    "        \n",
    "        table.sdf = table.sdf.join(\n",
    "            F.broadcast(self.cities.sdf),\n",
    "            on=table.sdf[table.city] == self.cities.sdf[self.cities.code],\n",
    "            how=\"left\",\n",
    "        ).drop(self.cities.code)\n",
    "\n",
    "        return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T16:37:43.773270Z",
     "start_time": "2021-11-19T16:37:43.754384Z"
    }
   },
   "outputs": [],
   "source": [
    "class TransformLinearly:\n",
    "    \n",
    "    def __init__(self, table: Table, transformations: List[Transformation]):\n",
    "        self.table = table\n",
    "        self.transformations = transformations\n",
    "\n",
    "    def run(self):\n",
    "        for transformation in self.transformations:\n",
    "            self.table = transformation.apply(self.table)\n",
    "\n",
    "        self.table.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order Created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T16:37:45.061943Z",
     "start_time": "2021-11-19T16:37:44.337929Z"
    }
   },
   "outputs": [],
   "source": [
    "order_created = OrderCreatedPort(spark, exec_date=date(2021, 11, 19), n_days=3)\n",
    "transformations = [\n",
    "    AddTimezone(CitiesPort(spark))\n",
    "]\n",
    "\n",
    "order_created_job = TransformLinearly(\n",
    "    table=order_created,\n",
    "    transformations=transformations,\n",
    ")\n",
    "order_created_job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T16:39:10.022058Z",
     "start_time": "2021-11-19T16:39:09.850987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+---------------+-------------+------------+\n",
      "|custom_attributes__city|p_creation_date|    time_zone|country_code|\n",
      "+-----------------------+---------------+-------------+------------+\n",
      "|                    BCN|     2021-11-19|Europe/Madrid|          ES|\n",
      "|                    BCN|     2021-11-18|Europe/Madrid|          ES|\n",
      "|                    CAG|     2021-11-17|  Europe/Rome|          IT|\n",
      "+-----------------------+---------------+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.table(f\"{order_created.database_out}.{order_created.name}\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
